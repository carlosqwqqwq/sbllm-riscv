{"id": "test_rvv_1", "idx": 10001, "query": "void memcpy_scalar(void* dest, const void* src, size_t n) { char* d = (char*)dest; const char* s = (const char*)src; while (n--) *d++ = *s++; }", "code_v0_no_empty_lines": "void memcpy_scalar(void* dest, const void* src, size_t n) { char* d = (char*)dest; const char* s = (const char*)src; while (n--) *d++ = *s++; }", "lang": "riscv", "benchmark_name": "memcpy", "prediction": ["#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V using vector intrinsics (RVV 1.0)\n// Assumes RV64GCV target with Zbb and Zba extensions\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle very small copies (<= 8 bytes) with branchless sequence\n    if (n <= 8) {\n        if (n & 0x4) {\n            *(uint32_t*)d = *(uint32_t*)s;\n            d += 4;\n            s += 4;\n        }\n        if (n & 0x2) {\n            *(uint16_t*)d = *(uint16_t*)s;\n            d += 2;\n            s += 2;\n        }\n        if (n & 0x1) {\n            *d = *s;\n        }\n        return;\n    }\n\n    // Align destination to 8-byte boundary for word copies\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) {\n            *d++ = *s++;\n        }\n    }\n\n    // Use vector intrinsics for large copies if available\n#ifdef __riscv_vector\n    if (n >= 64) {\n        size_t vl;\n        for (; n >= 64; n -= vl) {\n            vl = __riscv_vsetvl_e8m8(n);\n            vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n            __riscv_vse8_v_i8m8(d, v, vl);\n            d += vl;\n            s += vl;\n        }\n    }\n#endif\n\n    // Word copy using 64-bit operations (benefits from Zba extensions)\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Handle remaining bytes (0-7)\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) {\n        *(uint32_t*)d = *(uint32_t*)s;\n        d += 4;\n        s += 4;\n    }\n    if (tail & 0x2) {\n        *(uint16_t*)d = *(uint16_t*)s;\n        d += 2;\n        s += 2;\n    }\n    if (tail & 0x1) {\n        *d = *s;\n    }\n}", "#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V with word-sized copies and optional vectorization\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle small copies branchlessly\n    if (n <= 8) {\n        if (n & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n        if (n & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n        if (n & 0x1) { *d = *s; }\n        return;\n    }\n\n    // Align destination to 8 bytes\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) *d++ = *s++;\n    }\n\n    // Word copy using 64-bit operations\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Unrolled loop for better pipeline utilization\n    while (words >= 4) {\n        *d64++ = *s64++;\n        *d64++ = *s64++;\n        *d64++ = *s64++;\n        *d64++ = *s64++;\n        words -= 4;\n    }\n    \n    // Remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Tail bytes\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n    if (tail & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n    if (tail & 0x1) { *d = *s; }\n}\n\n// Vectorized version for RISC-V with V extension\n#ifdef __riscv_v\n\n#include <riscv_vector.h>\n\nvoid memcpy_vector(void* restrict dest, const void* restrict src, size_t n) {\n    size_t vl;\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n    \n    // Use maximum vector length (m8) for best throughput\n    for (; n > 0; n -= vl) {\n        vl = __riscv_vsetvl_e8m8(n);\n        vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n        __riscv_vse8_v_i8m8(d, v, vl);\n        s += vl;\n        d += vl;\n    }\n}\n\n#endif", "#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V with word-sized copies and optional vectorization\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle very small copies (n <= 8) with branchless sequence\n    if (n <= 8) {\n        // Use conditional moves based on bitmask\n        if (n & 0x4) {\n            *(uint32_t*)d = *(uint32_t*)s;\n            d += 4;\n            s += 4;\n        }\n        if (n & 0x2) {\n            *(uint16_t*)d = *(uint16_t*)s;\n            d += 2;\n            s += 2;\n        }\n        if (n & 0x1) {\n            *d = *s;\n        }\n        return;\n    }\n\n    // Align destination to 8-byte boundary for word copies\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        // Copy misaligned bytes\n        while (align--) {\n            *d++ = *s++;\n        }\n    }\n\n    // Use vector extension if available and beneficial (n >= 64)\n#ifdef __riscv_v\n    if (n >= 64) {\n        size_t vl;\n        for (; n >= 64; n -= vl) {\n            vl = __riscv_vsetvl_e8m8(n);\n            vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n            __riscv_vse8_v_i8m8(d, v, vl);\n            d += vl;\n            s += vl;\n        }\n    }\n#endif\n\n    // Word copy using 64-bit loads/stores\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Unrolled word copy (4 iterations per loop)\n    while (words >= 4) {\n        d64[0] = s64[0];\n        d64[1] = s64[1];\n        d64[2] = s64[2];\n        d64[3] = s64[3];\n        d64 += 4;\n        s64 += 4;\n        words -= 4;\n    }\n    \n    // Handle remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Handle tail bytes (0-7 bytes)\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) {\n        *(uint32_t*)d = *(uint32_t*)s;\n        d += 4;\n        s += 4;\n    }\n    if (tail & 0x2) {\n        *(uint16_t*)d = *(uint16_t*)s;\n        d += 2;\n        s += 2;\n    }\n    if (tail & 0x1) {\n        *d = *s;\n    }\n}", "#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V using word-sized copies and loop unrolling\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle small copies efficiently\n    if (n <= 16) {\n        // Branchless handling for up to 16 bytes\n        if (n & 0x8) { *(uint64_t*)d = *(uint64_t*)s; d += 8; s += 8; }\n        if (n & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n        if (n & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n        if (n & 0x1) { *d = *s; }\n        return;\n    }\n\n    // Align destination to 8-byte boundary\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) *d++ = *s++;\n    }\n\n    // Word copy with 4x unrolling\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Main unrolled loop\n    while (words >= 4) {\n        uint64_t w0 = s64[0];\n        uint64_t w1 = s64[1];\n        uint64_t w2 = s64[2];\n        uint64_t w3 = s64[3];\n        \n        d64[0] = w0;\n        d64[1] = w1;\n        d64[2] = w2;\n        d64[3] = w3;\n        \n        s64 += 4;\n        d64 += 4;\n        words -= 4;\n    }\n    \n    // Remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Handle tail bytes\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n    if (tail & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n    if (tail & 0x1) { *d = *s; }\n}\n\n// Vector-accelerated memcpy for RISC-V with RVV 1.0\n#ifdef __riscv_v\n#include <riscv_vector.h>\n\nvoid memcpy_vector(void* restrict dest, const void* restrict src, size_t n) {\n    size_t vl;\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n    \n    // Use largest vector length available (LMUL=8)\n    for (; n > 0; n -= vl) {\n        vl = __riscv_vsetvl_e8m8(n);\n        vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n        __riscv_vse8_v_i8m8(d, v, vl);\n        s += vl;\n        d += vl;\n    }\n}\n#endif", "#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V with word-sized copies, loop unrolling, and vectorization\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle small copies branchlessly (n <= 8)\n    if (n <= 8) {\n        if (n & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n        if (n & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n        if (n & 0x1) { *d = *s; }\n        return;\n    }\n\n    // Align destination to 8 bytes using byte copies\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) *d++ = *s++;\n    }\n\n    // Use RISC-V Vector extension if available for large copies (n >= 256)\n#ifdef __riscv_v\n    if (n >= 256) {\n        size_t vl;\n        for (; n > 0; n -= vl) {\n            vl = __riscv_vsetvl_e8m8(n);\n            vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n            __riscv_vse8_v_i8m8(d, v, vl);\n            s += vl;\n            d += vl;\n        }\n        return;\n    }\n#endif\n\n    // Word copy with loop unrolling (8 words per iteration)\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Unrolled loop for better pipeline utilization\n    while (words >= 8) {\n        // Use inline assembly for optimal load/store sequences\n        asm volatile (\n            \"ld t0, 0(%[src])\\n\\t\"\n            \"ld t1, 8(%[src])\\n\\t\"\n            \"ld t2, 16(%[src])\\n\\t\"\n            \"ld t3, 24(%[src])\\n\\t\"\n            \"ld t4, 32(%[src])\\n\\t\"\n            \"ld t5, 40(%[src])\\n\\t\"\n            \"ld t6, 48(%[src])\\n\\t\"\n            \"a7, 56(%[src])\\n\\t\"\n            \"sd t0, 0(%[dst])\\n\\t\"\n            \"sd t1, 8(%[dst])\\n\\t\"\n            \"sd t2, 16(%[dst])\\n\\t\"\n            \"sd t3, 24(%[dst])\\n\\t\"\n            \"sd t4, 32(%[dst])\\n\\t\"\n            \"sd t5, 40(%[dst])\\n\\t\"\n            \"sd t6, 48(%[dst])\\n\\t\"\n            \"sd a7, 56(%[dst])\\n\\t\"\n            : : [src]\"r\"(s64), [dst]\"r\"(d64)\n            : \"t0\", \"t1\", \"t2\", \"t3\", \"t4\", \"t5\", \"t6\", \"a7\", \"memory\"\n        );\n        s64 += 8;\n        d64 += 8;\n        words -= 8;\n    }\n    \n    // Remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Tail bytes (0-7 bytes)\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n    if (tail & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n    if (tail & 0x1) { *d = *s; }\n}"], "detailed_prediction": [{"message": {"content": "```c\n#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V using vector intrinsics (RVV 1.0)\n// Assumes RV64GCV target with Zbb and Zba extensions\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle very small copies (<= 8 bytes) with branchless sequence\n    if (n <= 8) {\n        if (n & 0x4) {\n            *(uint32_t*)d = *(uint32_t*)s;\n            d += 4;\n            s += 4;\n        }\n        if (n & 0x2) {\n            *(uint16_t*)d = *(uint16_t*)s;\n            d += 2;\n            s += 2;\n        }\n        if (n & 0x1) {\n            *d = *s;\n        }\n        return;\n    }\n\n    // Align destination to 8-byte boundary for word copies\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) {\n            *d++ = *s++;\n        }\n    }\n\n    // Use vector intrinsics for large copies if available\n#ifdef __riscv_vector\n    if (n >= 64) {\n        size_t vl;\n        for (; n >= 64; n -= vl) {\n            vl = __riscv_vsetvl_e8m8(n);\n            vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n            __riscv_vse8_v_i8m8(d, v, vl);\n            d += vl;\n            s += vl;\n        }\n    }\n#endif\n\n    // Word copy using 64-bit operations (benefits from Zba extensions)\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Handle remaining bytes (0-7)\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) {\n        *(uint32_t*)d = *(uint32_t*)s;\n        d += 4;\n        s += 4;\n    }\n    if (tail & 0x2) {\n        *(uint16_t*)d = *(uint16_t*)s;\n        d += 2;\n        s += 2;\n    }\n    if (tail & 0x1) {\n        *d = *s;\n    }\n}\n```"}}, {"message": {"content": "```c\n#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V with word-sized copies and optional vectorization\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle small copies branchlessly\n    if (n <= 8) {\n        if (n & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n        if (n & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n        if (n & 0x1) { *d = *s; }\n        return;\n    }\n\n    // Align destination to 8 bytes\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) *d++ = *s++;\n    }\n\n    // Word copy using 64-bit operations\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Unrolled loop for better pipeline utilization\n    while (words >= 4) {\n        *d64++ = *s64++;\n        *d64++ = *s64++;\n        *d64++ = *s64++;\n        *d64++ = *s64++;\n        words -= 4;\n    }\n    \n    // Remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Tail bytes\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n    if (tail & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n    if (tail & 0x1) { *d = *s; }\n}\n\n// Vectorized version for RISC-V with V extension\n#ifdef __riscv_v\n\n#include <riscv_vector.h>\n\nvoid memcpy_vector(void* restrict dest, const void* restrict src, size_t n) {\n    size_t vl;\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n    \n    // Use maximum vector length (m8) for best throughput\n    for (; n > 0; n -= vl) {\n        vl = __riscv_vsetvl_e8m8(n);\n        vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n        __riscv_vse8_v_i8m8(d, v, vl);\n        s += vl;\n        d += vl;\n    }\n}\n\n#endif\n```"}}, {"message": {"content": "```c\n#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V with word-sized copies and optional vectorization\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle very small copies (n <= 8) with branchless sequence\n    if (n <= 8) {\n        // Use conditional moves based on bitmask\n        if (n & 0x4) {\n            *(uint32_t*)d = *(uint32_t*)s;\n            d += 4;\n            s += 4;\n        }\n        if (n & 0x2) {\n            *(uint16_t*)d = *(uint16_t*)s;\n            d += 2;\n            s += 2;\n        }\n        if (n & 0x1) {\n            *d = *s;\n        }\n        return;\n    }\n\n    // Align destination to 8-byte boundary for word copies\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        // Copy misaligned bytes\n        while (align--) {\n            *d++ = *s++;\n        }\n    }\n\n    // Use vector extension if available and beneficial (n >= 64)\n#ifdef __riscv_v\n    if (n >= 64) {\n        size_t vl;\n        for (; n >= 64; n -= vl) {\n            vl = __riscv_vsetvl_e8m8(n);\n            vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n            __riscv_vse8_v_i8m8(d, v, vl);\n            d += vl;\n            s += vl;\n        }\n    }\n#endif\n\n    // Word copy using 64-bit loads/stores\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Unrolled word copy (4 iterations per loop)\n    while (words >= 4) {\n        d64[0] = s64[0];\n        d64[1] = s64[1];\n        d64[2] = s64[2];\n        d64[3] = s64[3];\n        d64 += 4;\n        s64 += 4;\n        words -= 4;\n    }\n    \n    // Handle remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Handle tail bytes (0-7 bytes)\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) {\n        *(uint32_t*)d = *(uint32_t*)s;\n        d += 4;\n        s += 4;\n    }\n    if (tail & 0x2) {\n        *(uint16_t*)d = *(uint16_t*)s;\n        d += 2;\n        s += 2;\n    }\n    if (tail & 0x1) {\n        *d = *s;\n    }\n}\n```"}}, {"message": {"content": "```c\n#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V using word-sized copies and loop unrolling\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle small copies efficiently\n    if (n <= 16) {\n        // Branchless handling for up to 16 bytes\n        if (n & 0x8) { *(uint64_t*)d = *(uint64_t*)s; d += 8; s += 8; }\n        if (n & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n        if (n & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n        if (n & 0x1) { *d = *s; }\n        return;\n    }\n\n    // Align destination to 8-byte boundary\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) *d++ = *s++;\n    }\n\n    // Word copy with 4x unrolling\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Main unrolled loop\n    while (words >= 4) {\n        uint64_t w0 = s64[0];\n        uint64_t w1 = s64[1];\n        uint64_t w2 = s64[2];\n        uint64_t w3 = s64[3];\n        \n        d64[0] = w0;\n        d64[1] = w1;\n        d64[2] = w2;\n        d64[3] = w3;\n        \n        s64 += 4;\n        d64 += 4;\n        words -= 4;\n    }\n    \n    // Remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Handle tail bytes\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n    if (tail & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n    if (tail & 0x1) { *d = *s; }\n}\n\n// Vector-accelerated memcpy for RISC-V with RVV 1.0\n#ifdef __riscv_v\n#include <riscv_vector.h>\n\nvoid memcpy_vector(void* restrict dest, const void* restrict src, size_t n) {\n    size_t vl;\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n    \n    // Use largest vector length available (LMUL=8)\n    for (; n > 0; n -= vl) {\n        vl = __riscv_vsetvl_e8m8(n);\n        vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n        __riscv_vse8_v_i8m8(d, v, vl);\n        s += vl;\n        d += vl;\n    }\n}\n#endif\n```"}}, {"message": {"content": "```c\n#include <stdint.h>\n#include <stddef.h>\n\n// Optimized memcpy for RISC-V with word-sized copies, loop unrolling, and vectorization\nvoid memcpy_opt(void* restrict dest, const void* restrict src, size_t n) {\n    uint8_t* d = (uint8_t*)dest;\n    const uint8_t* s = (const uint8_t*)src;\n\n    // Handle small copies branchlessly (n <= 8)\n    if (n <= 8) {\n        if (n & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n        if (n & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n        if (n & 0x1) { *d = *s; }\n        return;\n    }\n\n    // Align destination to 8 bytes using byte copies\n    size_t align = (uintptr_t)d & 0x7;\n    if (align) {\n        align = 8 - align;\n        n -= align;\n        while (align--) *d++ = *s++;\n    }\n\n    // Use RISC-V Vector extension if available for large copies (n >= 256)\n#ifdef __riscv_v\n    if (n >= 256) {\n        size_t vl;\n        for (; n > 0; n -= vl) {\n            vl = __riscv_vsetvl_e8m8(n);\n            vint8m8_t v = __riscv_vle8_v_i8m8(s, vl);\n            __riscv_vse8_v_i8m8(d, v, vl);\n            s += vl;\n            d += vl;\n        }\n        return;\n    }\n#endif\n\n    // Word copy with loop unrolling (8 words per iteration)\n    size_t words = n >> 3;\n    uint64_t* d64 = (uint64_t*)d;\n    const uint64_t* s64 = (const uint64_t*)s;\n    \n    // Unrolled loop for better pipeline utilization\n    while (words >= 8) {\n        // Use inline assembly for optimal load/store sequences\n        asm volatile (\n            \"ld t0, 0(%[src])\\n\\t\"\n            \"ld t1, 8(%[src])\\n\\t\"\n            \"ld t2, 16(%[src])\\n\\t\"\n            \"ld t3, 24(%[src])\\n\\t\"\n            \"ld t4, 32(%[src])\\n\\t\"\n            \"ld t5, 40(%[src])\\n\\t\"\n            \"ld t6, 48(%[src])\\n\\t\"\n            \"a7, 56(%[src])\\n\\t\"\n            \"sd t0, 0(%[dst])\\n\\t\"\n            \"sd t1, 8(%[dst])\\n\\t\"\n            \"sd t2, 16(%[dst])\\n\\t\"\n            \"sd t3, 24(%[dst])\\n\\t\"\n            \"sd t4, 32(%[dst])\\n\\t\"\n            \"sd t5, 40(%[dst])\\n\\t\"\n            \"sd t6, 48(%[dst])\\n\\t\"\n            \"sd a7, 56(%[dst])\\n\\t\"\n            : : [src]\"r\"(s64), [dst]\"r\"(d64)\n            : \"t0\", \"t1\", \"t2\", \"t3\", \"t4\", \"t5\", \"t6\", \"a7\", \"memory\"\n        );\n        s64 += 8;\n        d64 += 8;\n        words -= 8;\n    }\n    \n    // Remaining words\n    while (words--) {\n        *d64++ = *s64++;\n    }\n\n    // Tail bytes (0-7 bytes)\n    size_t tail = n & 0x7;\n    d = (uint8_t*)d64;\n    s = (const uint8_t*)s64;\n    if (tail & 0x4) { *(uint32_t*)d = *(uint32_t*)s; d += 4; s += 4; }\n    if (tail & 0x2) { *(uint16_t*)d = *(uint16_t*)s; d += 2; s += 2; }\n    if (tail & 0x1) { *d = *s; }\n}\n```"}}]}
